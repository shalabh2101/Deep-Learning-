{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "258_lab1_Kaggle_Challange.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBAQEslAzTye"
      },
      "source": [
        "# Kaggle Challange"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j0wMJvpkR_x"
      },
      "source": [
        "# importing Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout,BatchNormalization,UpSampling2D\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import PIL\n",
        "import PIL.Image as pim\n",
        "from keras.applications import VGG19,ResNet50\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r73TQ6uGlPYs"
      },
      "source": [
        "# Loading DataSet\n",
        "train_data=pd.read_csv('/content/train_data.csv')\n",
        "train_label=pd.read_csv('/content/train_label.csv')\n",
        "test_data=pd.read_csv('/content/test_data.csv',header=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS0qzAe-yhKJ",
        "outputId": "8bef7d3a-2c01-4620-8e0d-d365035d65b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Reshaping the data in the Desired format\n",
        "label=train_label['label'][1:]\n",
        "train_data=np.array(train_data)\n",
        "train_data=train_data.reshape(9999,32,32,3)\n",
        "testdata=np.array(test_data)\n",
        "testdata=testdata.reshape(2000,32,32,3)\n",
        "testdata.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBAWMl3bsVHG"
      },
      "source": [
        "# Played with Model Configuration, changes the optimisers, validation split for diffrent results\n",
        "\n",
        "# Model configuration\n",
        "batch_size = 50\n",
        "img_width, img_height, img_num_channels = 32, 32, 3\n",
        "loss_function = sparse_categorical_crossentropy\n",
        "no_classes = 100\n",
        "no_epochs = 100\n",
        "optimizer = Adam()\n",
        "# optimizer=SGD()\n",
        "validation_split = 0.2\n",
        "verbosity = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv8I1GMLpdX4"
      },
      "source": [
        "\n",
        "# Determine shape of the data\n",
        "input_shape = (img_width, img_height, img_num_channels)\n",
        "\n",
        "# Parse numbers as floats\n",
        "input_train = train_data.astype('float32')\n",
        "input_test=testdata.astype('float32')\n",
        "\n",
        "# Normalize data\n",
        "input_train = input_train / 255\n",
        "input_test=input_test/255\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncOH5A2OUyVV"
      },
      "source": [
        "# Generated additional images using trained Data. Played with Multiple parameters in image generation\n",
        "\n",
        "# image_generator = ImageDataGenerator(\n",
        "# rotation_range=45,\n",
        "# width_shift_range=.15,\n",
        "# height_shift_range=.15,\n",
        "# horizontal_flip=True,\n",
        "# zoom_range=0.5)\n",
        "\n",
        "image_generator = ImageDataGenerator(\n",
        "\t\trotation_range=20,\n",
        "\t\tzoom_range=0.15,\n",
        "\t\twidth_shift_range=0.2,\n",
        "\t\theight_shift_range=0.2,\n",
        "\t\tshear_range=0.15,\n",
        "\t\thorizontal_flip=True,\n",
        "\t\tfill_mode=\"nearest\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ5S8ow_y9Jq"
      },
      "source": [
        "data_gen=image_generator.flow(input_train, label,\n",
        "            batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJLbNrXMFb5M"
      },
      "source": [
        "# Callback for stopping the model when reaches desired efficiency. Played with multiple efficiencies for diffrent models. Higher effccienies have led the \n",
        "# model to overfit and resulting in bad score\n",
        "ACCURACY_THRESHOLD = 0.85\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tif(logs.get('accuracy') > ACCURACY_THRESHOLD):\n",
        "\t\t\tself.model.stop_training = True\n",
        "\n",
        "# Instantiate a callback object\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqLV4udv1U9y"
      },
      "source": [
        "# Created model with few Convoluted layers.Although training accuracy was good ,score was bad. Model might be overfitting\n",
        "validation_split = 0.3\n",
        "# Create the model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(1024, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=loss_function,\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit data to model\n",
        "history = model.fit(input_train, label,\n",
        "            batch_size=batch_size,\n",
        "            epochs=no_epochs,\n",
        "            verbose=verbosity,\n",
        "            validation_split=validation_split, callbacks=[callbacks])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYsExO9i3uSx"
      },
      "source": [
        "# Trained the model on the more training data generated by the image generator. Played with multiple parameters. Score was better than the above model\n",
        "\n",
        "# Create the model\n",
        "validation_split = 0.2\n",
        "no_epochs = 300\n",
        "#third4.csv 29.85 with epoch 100\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='elu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(Dense(128, activation='elu'))\n",
        "model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=loss_function,\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit data to model\n",
        "history = model.fit(image_generator.flow(input_train, label,\n",
        "            batch_size=batch_size),\n",
        "            epochs=no_epochs,\n",
        "            verbose=verbosity,\n",
        "            # validation_split=validation_split, \n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYPCuE9uClbT",
        "outputId": "dddc4c85-4b95-43bc-f1b9-bb296d839e8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Utilize Transfer Learning ResNet50 model and ran experiements for many variations in parameters.\n",
        "# This would normally take 2 to 5 hours of training deoending on the parameters. Score has significantly improved using the transfer learning.\n",
        "\n",
        "no_epochs=250\n",
        "ACCURACY_THRESHOLD = 0.85\n",
        "optimizer=Adam()\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = Sequential()\n",
        "model.add(UpSampling2D())\n",
        "model.add(UpSampling2D())\n",
        "model.add(UpSampling2D())\n",
        "model.add(resnet_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(.25))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(.25))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "for layer in resnet_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "# Compile the model\n",
        "model.compile(loss=loss_function,\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit data to model\n",
        "history = model.fit(image_generator.flow(input_train, label,\n",
        "            batch_size=batch_size),\n",
        "            epochs=no_epochs,\n",
        "            verbose=verbosity,\n",
        "            # validation_split=validation_split, \n",
        "            callbacks=[callbacks])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_4:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (50, 256, 256, 3).\n",
            "Epoch 1/250\n",
            "200/200 [==============================] - 91s 457ms/step - loss: 4.0565 - accuracy: 0.1052\n",
            "Epoch 2/250\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 3.0679 - accuracy: 0.2309\n",
            "Epoch 3/250\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 2.6285 - accuracy: 0.3171\n",
            "Epoch 4/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 2.3199 - accuracy: 0.3817\n",
            "Epoch 5/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 2.1359 - accuracy: 0.4127\n",
            "Epoch 6/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 1.9773 - accuracy: 0.4535\n",
            "Epoch 7/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 1.8581 - accuracy: 0.4854\n",
            "Epoch 8/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.7678 - accuracy: 0.5036\n",
            "Epoch 9/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.6911 - accuracy: 0.5224\n",
            "Epoch 10/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.6198 - accuracy: 0.5412\n",
            "Epoch 11/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.5500 - accuracy: 0.5557\n",
            "Epoch 12/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.4863 - accuracy: 0.5725\n",
            "Epoch 13/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.4185 - accuracy: 0.5830\n",
            "Epoch 14/250\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 1.3851 - accuracy: 0.5932\n",
            "Epoch 15/250\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 1.3352 - accuracy: 0.6113\n",
            "Epoch 16/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.2867 - accuracy: 0.6207\n",
            "Epoch 17/250\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 1.2490 - accuracy: 0.6268\n",
            "Epoch 18/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.2193 - accuracy: 0.6373\n",
            "Epoch 19/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 1.1858 - accuracy: 0.6474\n",
            "Epoch 20/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.1507 - accuracy: 0.6629\n",
            "Epoch 21/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.1197 - accuracy: 0.6651\n",
            "Epoch 22/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.1060 - accuracy: 0.6680\n",
            "Epoch 23/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.0930 - accuracy: 0.6726\n",
            "Epoch 24/250\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 1.0719 - accuracy: 0.6824\n",
            "Epoch 25/250\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 1.0270 - accuracy: 0.6874\n",
            "Epoch 26/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.0306 - accuracy: 0.6867\n",
            "Epoch 27/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 1.0104 - accuracy: 0.6982\n",
            "Epoch 28/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.9860 - accuracy: 0.6982\n",
            "Epoch 29/250\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 0.9699 - accuracy: 0.7103\n",
            "Epoch 30/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.9426 - accuracy: 0.7144\n",
            "Epoch 31/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.9372 - accuracy: 0.7168\n",
            "Epoch 32/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.8805 - accuracy: 0.7301\n",
            "Epoch 33/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.9157 - accuracy: 0.7204\n",
            "Epoch 34/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.8671 - accuracy: 0.7386\n",
            "Epoch 35/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.8467 - accuracy: 0.7391\n",
            "Epoch 36/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.8319 - accuracy: 0.7467\n",
            "Epoch 37/250\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 0.8316 - accuracy: 0.7420\n",
            "Epoch 38/250\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 0.8138 - accuracy: 0.7511\n",
            "Epoch 39/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.8056 - accuracy: 0.7575\n",
            "Epoch 40/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.7835 - accuracy: 0.7565\n",
            "Epoch 41/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.7885 - accuracy: 0.7564\n",
            "Epoch 42/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.7657 - accuracy: 0.7644\n",
            "Epoch 43/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.7797 - accuracy: 0.7596\n",
            "Epoch 44/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.7399 - accuracy: 0.7721\n",
            "Epoch 45/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.7569 - accuracy: 0.7679\n",
            "Epoch 46/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.7386 - accuracy: 0.7712\n",
            "Epoch 47/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.7356 - accuracy: 0.7743\n",
            "Epoch 48/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.7028 - accuracy: 0.7831\n",
            "Epoch 49/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.6971 - accuracy: 0.7787\n",
            "Epoch 50/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.6843 - accuracy: 0.7920\n",
            "Epoch 51/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.6941 - accuracy: 0.7830\n",
            "Epoch 52/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.6870 - accuracy: 0.7861\n",
            "Epoch 53/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.6694 - accuracy: 0.7942\n",
            "Epoch 54/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.6712 - accuracy: 0.7895\n",
            "Epoch 55/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.6798 - accuracy: 0.7884\n",
            "Epoch 56/250\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.6362 - accuracy: 0.8017\n",
            "Epoch 57/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.6068 - accuracy: 0.8115\n",
            "Epoch 58/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.6228 - accuracy: 0.8049\n",
            "Epoch 59/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.6165 - accuracy: 0.8066\n",
            "Epoch 60/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.6180 - accuracy: 0.8077\n",
            "Epoch 61/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.6040 - accuracy: 0.8134\n",
            "Epoch 62/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.6052 - accuracy: 0.8148\n",
            "Epoch 63/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.6030 - accuracy: 0.8096\n",
            "Epoch 64/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.5785 - accuracy: 0.8177\n",
            "Epoch 65/250\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 0.5818 - accuracy: 0.8169\n",
            "Epoch 66/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.6008 - accuracy: 0.8144\n",
            "Epoch 67/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.5754 - accuracy: 0.8213\n",
            "Epoch 68/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.5581 - accuracy: 0.8222\n",
            "Epoch 69/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.5672 - accuracy: 0.8238\n",
            "Epoch 70/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.5457 - accuracy: 0.8294\n",
            "Epoch 71/250\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.5633 - accuracy: 0.8209\n",
            "Epoch 72/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.5260 - accuracy: 0.8321\n",
            "Epoch 73/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.5450 - accuracy: 0.8311\n",
            "Epoch 74/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.5496 - accuracy: 0.8300\n",
            "Epoch 75/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.5231 - accuracy: 0.8371\n",
            "Epoch 76/250\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.4951 - accuracy: 0.8442\n",
            "Epoch 77/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.5311 - accuracy: 0.8295\n",
            "Epoch 78/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.5098 - accuracy: 0.8384\n",
            "Epoch 79/250\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.5073 - accuracy: 0.8402\n",
            "Epoch 80/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.4910 - accuracy: 0.8457\n",
            "Epoch 81/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.4882 - accuracy: 0.8478\n",
            "Epoch 82/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.4951 - accuracy: 0.8458\n",
            "Epoch 83/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.4977 - accuracy: 0.8433\n",
            "Epoch 84/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.4588 - accuracy: 0.8627\n",
            "Epoch 85/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.4524 - accuracy: 0.8533\n",
            "Epoch 86/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.4917 - accuracy: 0.8477\n",
            "Epoch 87/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.4866 - accuracy: 0.8462\n",
            "Epoch 88/250\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.4669 - accuracy: 0.8538\n",
            "Epoch 89/250\n",
            "  1/200 [..............................] - ETA: 0s - loss: 0.3815 - accuracy: 0.8600"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpxB_PkdtJlE"
      },
      "source": [
        "predictions=model.predict(input_test)\n",
        "pred=tf.argmax(predictions, 1)\n",
        "new=np.array(pred)\n",
        "\n",
        "final=pd.concat([test_data.index.to_frame(),pd.DataFrame(new)],axis=1)\n",
        "final.columns=['id','label']\n",
        "FILE_NAME='final_11'+'.csv'\n",
        "final.to_csv('/content/'+FILE_NAME,index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}