{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diabetes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9gDBYOgb5op",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcdf9ba9-8f8a-4696-a43e-a9298a2bf4b4"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Sc95bydby4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f181d41-07ef-4251-8d20-ab08d7c58cca"
      },
      "source": [
        "import numpy as np;\n",
        "import pandas as pd;\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz3rWrNvdjHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading data\n",
        "data=pd.read_csv('/content/diabetes.csv');"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVmtza1jdqNJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b967a46-e432-4da7-e1ba-d5e3c4fabc78"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(758, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkZqJyb4fJtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Naming the columns name\n",
        "data.columns=['Feature 1','Feature 2','Feature 3','Feature 4','Feature 5','Feature 6','Feature 7','Feature 8','Output']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B69ghBntdtOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "58b59ffb-84c7-4300-e86b-629db48e07a3"
      },
      "source": [
        "# Checking the Null values in the data\n",
        "data.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 758 entries, 0 to 757\n",
            "Data columns (total 9 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       758 non-null    float64\n",
            " 1   1       758 non-null    float64\n",
            " 2   2       758 non-null    float64\n",
            " 3   3       758 non-null    float64\n",
            " 4   4       758 non-null    float64\n",
            " 5   5       758 non-null    float64\n",
            " 6   6       758 non-null    float64\n",
            " 7   7       758 non-null    float64\n",
            " 8   Output  758 non-null    int64  \n",
            "dtypes: float64(8), int64(1)\n",
            "memory usage: 53.4 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNTIYTvHf8pQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "167a6826-3d0a-4c88-8457-643c53308cd4"
      },
      "source": [
        "#Checking the Data distribution\n",
        "data.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>758.000000</td>\n",
              "      <td>758.000000</td>\n",
              "      <td>758.000000</td>\n",
              "      <td>758.000000</td>\n",
              "      <td>758.000000</td>\n",
              "      <td>758.000000</td>\n",
              "      <td>758.000000</td>\n",
              "      <td>758.000000</td>\n",
              "      <td>758.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.407807</td>\n",
              "      <td>0.218208</td>\n",
              "      <td>0.176500</td>\n",
              "      <td>-0.289731</td>\n",
              "      <td>-0.323961</td>\n",
              "      <td>-0.032289</td>\n",
              "      <td>-0.663427</td>\n",
              "      <td>-0.516799</td>\n",
              "      <td>0.654354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.386493</td>\n",
              "      <td>0.306465</td>\n",
              "      <td>0.201420</td>\n",
              "      <td>0.258651</td>\n",
              "      <td>0.375608</td>\n",
              "      <td>0.205508</td>\n",
              "      <td>0.283202</td>\n",
              "      <td>0.400674</td>\n",
              "      <td>0.475893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.882353</td>\n",
              "      <td>-0.557789</td>\n",
              "      <td>-0.606557</td>\n",
              "      <td>-0.858586</td>\n",
              "      <td>-0.966903</td>\n",
              "      <td>-0.457526</td>\n",
              "      <td>-0.994876</td>\n",
              "      <td>-0.966667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.764706</td>\n",
              "      <td>-0.005025</td>\n",
              "      <td>0.016393</td>\n",
              "      <td>-0.494949</td>\n",
              "      <td>-0.716312</td>\n",
              "      <td>-0.179583</td>\n",
              "      <td>-0.858241</td>\n",
              "      <td>-0.866667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.529412</td>\n",
              "      <td>0.165829</td>\n",
              "      <td>0.180328</td>\n",
              "      <td>-0.292929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.034277</td>\n",
              "      <td>-0.748506</td>\n",
              "      <td>-0.633333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.407035</td>\n",
              "      <td>0.311475</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.087928</td>\n",
              "      <td>-0.532451</td>\n",
              "      <td>-0.233333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                0           1           2  ...           6           7      Output\n",
              "count  758.000000  758.000000  758.000000  ...  758.000000  758.000000  758.000000\n",
              "mean    -0.407807    0.218208    0.176500  ...   -0.663427   -0.516799    0.654354\n",
              "std      0.386493    0.306465    0.201420  ...    0.283202    0.400674    0.475893\n",
              "min     -0.882353   -0.557789   -0.606557  ...   -0.994876   -0.966667    0.000000\n",
              "25%     -0.764706   -0.005025    0.016393  ...   -0.858241   -0.866667    0.000000\n",
              "50%     -0.529412    0.165829    0.180328  ...   -0.748506   -0.633333    1.000000\n",
              "75%      0.000000    0.407035    0.311475  ...   -0.532451   -0.233333    1.000000\n",
              "max      1.000000    1.000000    1.000000  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0gtRqxlgEts",
        "colab_type": "text"
      },
      "source": [
        "It seems that data is already normalized as each feature range is between (-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0W36BhWgCWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that creates a blank session\n",
        "# Used for clearing variables between sessions\n",
        "def tf_reset():\n",
        "    try:\n",
        "        sess.close()\n",
        "    except:\n",
        "        pass\n",
        "    tf.reset_default_graph()\n",
        "    return tf.Session()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEVC1XmMifH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dividing inputs and outputs \n",
        "inputs=data.iloc[:,:-1].values\n",
        "outputs=data.iloc[:,-1].values\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmgKDWuskq5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d0c4a74-eda4-4358-81d9-cac7daabc571"
      },
      "source": [
        "# Adding the new axis to output\n",
        "outputs = outputs[:,np.newaxis]\n",
        "print(outputs.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(758, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z01ZdxPYsEcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the data into training and testing data with 80:20 ratio\n",
        "from sklearn import  model_selection\n",
        "data_train, data_test, label_train, label_test = model_selection.train_test_split(inputs, outputs, \\\n",
        "                                                                                 test_size=0.2, random_state = 258)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VF4-2YefxF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3cf00ad8-07ef-4688-a98d-5a79f4fdaae8"
      },
      "source": [
        "# Model with Hypothesis one\n",
        "sess = tf_reset()\n",
        "\n",
        "def create_model():\n",
        "    # create inputs\n",
        "    input_ph = tf.placeholder(dtype=tf.float32, shape=[None, 8]) # Since we know the shape of the data we can manually input\n",
        "    output_ph = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
        "\n",
        "    # create variables\n",
        "    W0 = tf.get_variable(name='W0', shape=[8, 20], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    W1 = tf.get_variable(name='W1', shape=[20, 20], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    W2 = tf.get_variable(name='W2', shape=[20, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
        "\n",
        "    b0 = tf.get_variable(name='b0', shape=[20], initializer=tf.constant_initializer(0.))\n",
        "    b1 = tf.get_variable(name='b1', shape=[20], initializer=tf.constant_initializer(0.))\n",
        "    b2 = tf.get_variable(name='b2', shape=[1], initializer=tf.constant_initializer(0.))\n",
        "\n",
        "    weights = [W0, W1, W2]\n",
        "    biases = [b0, b1, b2]\n",
        "    activations = [tf.nn.relu, tf.nn.relu, None]\n",
        "\n",
        "    # create computation graph\n",
        "    layer = input_ph\n",
        "    for W, b, activation in zip(weights, biases, activations):\n",
        "        layer = tf.matmul(layer, W) + b\n",
        "        if activation is not None:\n",
        "            layer = activation(layer)\n",
        "    output_pred = layer\n",
        "    \n",
        "    return input_ph, output_ph, output_pred\n",
        "    \n",
        "input_ph, output_ph, output_pred = create_model()\n",
        "    \n",
        "# create loss\n",
        "mse = tf.reduce_mean(0.5 * tf.square(output_pred - output_ph))\n",
        "\n",
        "# create optimizer\n",
        "\n",
        "opt = tf.train.AdamOptimizer().minimize(mse)\n",
        "\n",
        "# initialize variables\n",
        "sess.run(tf.global_variables_initializer())\n",
        "# create saver to save model variables\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# run training\n",
        "batch_size = 32\n",
        "for training_step in range(10000):\n",
        "    # get a random subset of the training data\n",
        "    indices = np.random.randint(low=0, high=len(data_train), size=batch_size)\n",
        "    input_batch = data_train[indices]\n",
        "    output_batch = label_train[indices]\n",
        "    \n",
        "    # run the optimizer and get the mse\n",
        "    _, mse_run = sess.run([opt, mse], feed_dict={input_ph: input_batch, output_ph: output_batch})\n",
        "    \n",
        "    # print the mse every so often\n",
        "    if training_step % 1000 == 0:\n",
        "        print('{0:04d} mse: {1:.3f}'.format(training_step, mse_run))\n",
        "        saver.save(sess, '/tmp/model_diabetes.ckpt')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0000 mse: 0.277\n",
            "1000 mse: 0.081\n",
            "2000 mse: 0.074\n",
            "3000 mse: 0.074\n",
            "4000 mse: 0.041\n",
            "5000 mse: 0.064\n",
            "6000 mse: 0.041\n",
            "7000 mse: 0.062\n",
            "8000 mse: 0.042\n",
            "9000 mse: 0.022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luNe5p7_YiXg",
        "colab_type": "text"
      },
      "source": [
        "In the above model, we have used optimizer=AdamOptimizer and batch size=32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zGmecfieWEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "fd5a0d5c-8579-4c6a-d8b6-64715df46bb4"
      },
      "source": [
        "# Prediction of  Result with the Hypothesis 1\n",
        "\n",
        "sess = tf_reset()\n",
        "\n",
        "# create the model\n",
        "input_ph, output_ph, output_pred = create_model()\n",
        "\n",
        "# restore the saved model\n",
        "saver = tf.train.Saver()\n",
        "saver.restore(sess, \"/tmp/model_diabetes.ckpt\")\n",
        "predictions= sess.run(output_pred, feed_dict={input_ph: data_test})\n",
        "pTClass = np.round(predictions)\n",
        "Predicted_Result = np.ravel(abs(pTClass)).astype(int)\n",
        "Actual_Result= np.ravel(label_test)\n",
        "print('Predicted test classes :')\n",
        "# print(np.ravel(abs(pTClass)))\n",
        "print(Predicted_Result)\n",
        "print('Actual test classes:')\n",
        "print(Actual_Result)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/model_diabetes.ckpt\n",
            "Predicted test classes :\n",
            "[0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0\n",
            " 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0\n",
            " 1 2 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 3 0 1 1 0 0 1\n",
            " 1 1 1 0]\n",
            "Actual test classes:\n",
            "[0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1\n",
            " 1 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwdNQRxvP3M7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5b9a6e1-5ca7-49ad-c22c-5d11d41c70f3"
      },
      "source": [
        "# Predicting the accuracy\n",
        "from sklearn import metrics\n",
        "print(metrics.accuracy_score(Actual_Result, Predicted_Result))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6578947368421053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fu0Om2vUbkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "bdb3e0b1-f6eb-42d2-f963-f3c227366d4e"
      },
      "source": [
        "# Creating Model with Hypothesis Two\n",
        "\n",
        "sess = tf_reset()\n",
        "\n",
        "def create_model():\n",
        "    # create inputs\n",
        "    input_ph = tf.placeholder(dtype=tf.float32, shape=[None, 8]) # Since we know the shape of the data we can manually input\n",
        "    output_ph = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
        "\n",
        "    # create variables\n",
        "    W0 = tf.get_variable(name='W0', shape=[8, 20], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    W1 = tf.get_variable(name='W1', shape=[20, 20], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    W2 = tf.get_variable(name='W2', shape=[20, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
        "\n",
        "    b0 = tf.get_variable(name='b0', shape=[20], initializer=tf.constant_initializer(0.))\n",
        "    b1 = tf.get_variable(name='b1', shape=[20], initializer=tf.constant_initializer(0.))\n",
        "    b2 = tf.get_variable(name='b2', shape=[1], initializer=tf.constant_initializer(0.))\n",
        "\n",
        "    weights = [W0, W1, W2]\n",
        "    biases = [b0, b1, b2]\n",
        "    activations = [tf.nn.relu, tf.nn.relu, None]\n",
        "\n",
        "    # create computation graph\n",
        "    layer = input_ph\n",
        "    for W, b, activation in zip(weights, biases, activations):\n",
        "        layer = tf.matmul(layer, W) + b\n",
        "        if activation is not None:\n",
        "            layer = activation(layer)\n",
        "    output_pred = layer\n",
        "    \n",
        "    return input_ph, output_ph, output_pred\n",
        "    \n",
        "input_ph, output_ph, output_pred = create_model()\n",
        "    \n",
        "# create loss\n",
        "mse = tf.reduce_mean(0.5 * tf.square(output_pred - output_ph))\n",
        "\n",
        "# create optimizer\n",
        "# opt = tf.train.AdamOptimizer().minimize(mse)\n",
        "opt = tf.train.GradientDescentOptimizer(0.01).minimize(mse)\n",
        "\n",
        "# initialize variables\n",
        "sess.run(tf.global_variables_initializer())\n",
        "# create saver to save model variables\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# run training\n",
        "batch_size = 40\n",
        "for training_step in range(40000):\n",
        "    # get a random subset of the training data\n",
        "    indices = np.random.randint(low=0, high=len(data_train), size=batch_size)\n",
        "    input_batch = data_train[indices]\n",
        "    output_batch = label_train[indices]\n",
        "    \n",
        "    # run the optimizer and get the mse\n",
        "    _, mse_run = sess.run([opt, mse], feed_dict={input_ph: input_batch, output_ph: output_batch})\n",
        "    \n",
        "    # print the mse every so often\n",
        "    if training_step % 5000 == 0:\n",
        "        print('{0:04d} mse: {1:.3f}'.format(training_step, mse_run))\n",
        "        saver.save(sess, '/tmp/model_diabetes2.ckpt')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0000 mse: 0.470\n",
            "5000 mse: 0.056\n",
            "10000 mse: 0.058\n",
            "15000 mse: 0.052\n",
            "20000 mse: 0.055\n",
            "25000 mse: 0.040\n",
            "30000 mse: 0.048\n",
            "35000 mse: 0.063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQcPgbVOZQYf",
        "colab_type": "text"
      },
      "source": [
        "In the above model,   Optimizer = GradientDescentOptimizer, batch size=40 and iterations=40000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrAMGjjYU3Ox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4e11124a-a57d-4f85-adf6-60e1bf15a32d"
      },
      "source": [
        "# Prediction of  Result with the Hypothesis 2\n",
        "\n",
        "sess = tf_reset()\n",
        "\n",
        "# create the model\n",
        "input_ph, output_ph, output_pred = create_model()\n",
        "\n",
        "# restore the saved model\n",
        "saver = tf.train.Saver()\n",
        "saver.restore(sess, \"/tmp/model_diabetes2.ckpt\")\n",
        "predictions= sess.run(output_pred, feed_dict={input_ph: data_test})\n",
        "pTClass = np.round(predictions)\n",
        "Predicted_Result = np.ravel(abs(pTClass)).astype(int)\n",
        "Actual_Result= np.ravel(label_test)\n",
        "print('Predicted test classes :')\n",
        "# print(np.ravel(abs(pTClass)))\n",
        "print(Predicted_Result)\n",
        "print('Actual test classes:')\n",
        "print(Actual_Result)\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/model_diabetes2.ckpt\n",
            "Predicted test classes :\n",
            "[0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 0 0 1 1 1 1 1 2 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1\n",
            " 1 1 0 0]\n",
            "Actual test classes:\n",
            "[0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1\n",
            " 1 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf6jzXzmU5oA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13687986-9f03-4bcf-9152-c9bba044df26"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.accuracy_score(Actual_Result, Predicted_Result))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7236842105263158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVxh_IS3ZgO_",
        "colab_type": "text"
      },
      "source": [
        "The tuning of parameters like  optimizer , batch size and number of iterations has helped in increasing the accuracy from 65.78% to 72.36 %. \n",
        "\n",
        "\n"
      ]
    }
  ]
}